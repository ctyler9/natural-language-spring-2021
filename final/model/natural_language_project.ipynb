{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "natural_language_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pio4uXlckHLa",
        "outputId": "2a7de272-20cf-416d-e5c6-25bf22c6cd27"
      },
      "source": [
        "!git clone https://karanshared:ThisIsTheGithubPassword@github.com/ctyler9/natural-language-spring-2021.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'natural-language-spring-2021'...\n",
            "remote: Enumerating objects: 270, done.\u001b[K\n",
            "remote: Counting objects: 100% (270/270), done.\u001b[K\n",
            "remote: Compressing objects: 100% (176/176), done.\u001b[K\n",
            "remote: Total 270 (delta 157), reused 180 (delta 87), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (270/270), 12.24 MiB | 16.64 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpXplPN6hHER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e74ea20-a5e0-44c9-fbbd-07e5daac9f40"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "%cd /content/natural-language-spring-2021/final/model\n",
        "from model_cnn import NBOW\n",
        "from model_attention import AttentionModel\n",
        "%cd /content/natural-language-spring-2021/data\n",
        "from vocab import Vocab, WSBDataScore, WSBDataStock, load_csv, create_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/natural-language-spring-2021/final/model\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/content/natural-language-spring-2021/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAydPisNu6Xi",
        "outputId": "4909c678-8e5c-4388-b2de-5abb0b347dae"
      },
      "source": [
        "!chmod 600 kaggle.json\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "!pip install -q kaggle\n",
        "!kaggle datasets download -d gpreda/reddit-wallstreetsbets-posts --unzip \n",
        "!kaggle datasets download -d yash612/stockmarket-sentiment-dataset --unzip\n",
        "# !kaggle datasets download -d jacksoncrow/stock-market-dataset --unzip\n",
        "#https://www.kaggle.com/gpreda/reddit-wallstreetsbets-posts?select=reddit_wsb.csv\n",
        "#https://www.kaggle.com/yash612/stockmarket-sentiment-dataset?select=stock_data.csv\n",
        "#https://www.kaggle.com/jacksoncrow/stock-market-dataset?select=symbols_valid_meta.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading reddit-wallstreetsbets-posts.zip to /content/natural-language-spring-2021/data\n",
            "100% 12.6M/12.6M [00:00<00:00, 50.3MB/s]\n",
            "\n",
            "Downloading stockmarket-sentiment-dataset.zip to /content/natural-language-spring-2021/data\n",
            "  0% 0.00/201k [00:00<?, ?B/s]\n",
            "100% 201k/201k [00:00<00:00, 62.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4268MXyDkyD7",
        "outputId": "f7be324c-0eff-4d99-874c-2f2662c27317"
      },
      "source": [
        "print(torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8_jO-fAhc1m"
      },
      "source": [
        "def eval_network(data, net, use_gpu=False, batch_size=25, device=torch.device('cpu')):\n",
        "    print(\"Evaluation Set\")\n",
        "    num_correct = 0\n",
        "    # Y = (data.labels + 1.0) / 2.0\n",
        "    X = data.XwordList\n",
        "    Y = data.Y\n",
        "    batch_predictions = []\n",
        "    for batch in tqdm(range(0, len(X), batch_size), leave=False):\n",
        "        batch_x = pad_batch_input(X[batch:batch + batch_size], device=device)\n",
        "        batch_y = torch.tensor(Y[batch:batch + batch_size], device=device)\n",
        "        batch_y_hat = net.forward(batch_x)\n",
        "        if type(batch_y_hat) == tuple: # tuple argument\n",
        "          batch_y_hat = batch_y_hat[0]\n",
        "        predictions = batch_y_hat.argmax(dim=1)\n",
        "        batch_predictions.append(predictions)\n",
        "        # num_correct = float((predictions == batch_y).sum())\n",
        "        # accuracy = num_correct/float(batch_size)\n",
        "        # batch_accuracies.append(accuracy)\n",
        "    predictions = torch.cat(batch_predictions)\n",
        "    predictions = predictions.type(torch.float64)\n",
        "    Y_tensor = torch.tensor(Y, device=device)\n",
        "    num_correct = float((predictions == Y_tensor).sum())\n",
        "    accuracy = num_correct/len(Y)\n",
        "\n",
        "    print(\"Eval Accuracy: %s\" % accuracy)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkiBlSIEhfWz"
      },
      "source": [
        "def SavePredictions(data, outFile, net):\n",
        "    fOut = open(outFile, 'w')\n",
        "    for i in range(len(data.XwordList)):\n",
        "        logProbs = net.forward(data.XwordList[i])\n",
        "        pred = torch.argmax(logProbs)\n",
        "        fOut.write(f\"{data.XfileList[i]}\\t{pred}\\n\")\n",
        "\n",
        "def convert_to_onehot(Y_list, NUM_CLASSES=2, device=torch.device('cpu')):\n",
        "    Y_onehot = torch.zeros((len(Y_list), NUM_CLASSES), device=device)\n",
        "    # Y_onehot = [torch.zeros(len(l), NUM_CLASSES) for l in Y_list]\n",
        "    for i in range(len(Y_list)):\n",
        "        Y_onehot[i, int(Y_list[i])]= 1.0\n",
        "    return Y_onehot\n",
        "\n",
        "\n",
        "def pad_batch_input(X_list, device=torch.device('cpu')):\n",
        "    X_padded = torch.nn.utils.rnn.pad_sequence([torch.as_tensor(l) for l in X_list], batch_first=True).type(torch.LongTensor).to(device)\n",
        "    # X_mask   = torch.nn.utils.rnn.pad_sequence([torch.as_tensor([1.0] * len(l)) for l in X_list], batch_first=True).type(torch.FloatTensor)\n",
        "    return X_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbthF44EiA-d"
      },
      "source": [
        "def train_network(net, X, Y, num_epochs, dev, lr=0.001, batchSize=50, use_gpu=False, num_classes=5, device=torch.device('cpu')):\n",
        "\n",
        "    print(\"Start Training!\")\n",
        "    #TODO: initialize optimizer.\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "    epoch_losses = []\n",
        "    eval_accuracy = []\n",
        "    for epoch in range(num_epochs):\n",
        "        num_correct = 0\n",
        "        total_loss = 0.0\n",
        "        net.train()   #Put the network into training model\n",
        "        for batch in tqdm(range(0, len(X), batchSize), leave=False):\n",
        "            batch_tweets = X[batch:batch + batchSize]\n",
        "            batch_labels = Y[batch:batch + batchSize]\n",
        "            batch_tweets = pad_batch_input(batch_tweets, device=device)\n",
        "            batch_onehot_labels = convert_to_onehot(batch_labels, NUM_CLASSES=num_classes, device=device)\n",
        "            optimizer.zero_grad()\n",
        "            batch_y_hat = net.forward(batch_tweets)\n",
        "            if type(batch_y_hat) == tuple:\n",
        "                batch_y_hat = batch_y_hat[0]\n",
        "            batch_losses = torch.neg(batch_y_hat)*batch_onehot_labels #cross entropy loss\n",
        "            loss = batch_losses.mean()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += float(loss.detach().item())\n",
        "\n",
        "        epoch_losses.append(total_loss)\n",
        "        net.eval()    #Switch to eval mode\n",
        "        print(f\"loss on epoch {epoch} = {total_loss}\")\n",
        "        accuracy = eval_network(dev, net, use_gpu=use_gpu, batch_size=batchSize, device=device)\n",
        "        eval_accuracy.append(accuracy)\n",
        "\n",
        "\n",
        "    print(\"Finished Training\")\n",
        "    return epoch_losses, eval_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8stELwNiDf7"
      },
      "source": [
        "def nbow(path=\"./reddit_wsb.csv\", n_classes=3, label_type=\"volitility\", device=\"gpu\", save_model=True):\n",
        "    if path == \"./reddit_wsb.csv\":\n",
        "      data = load_csv(path, \"reddit\")\n",
        "      vocab = create_vocab(data['title'].values)\n",
        "\n",
        "    split_point = int(len(data)*0.9)\n",
        "    train_df = data[0:split_point]\n",
        "    dev_df = data[split_point:]\n",
        "\n",
        "    print(\"load train data\")\n",
        "    if path == \"./reddit_wsb.csv\":\n",
        "      train_data = WSBDataStock(path, label_type=\"volitility\", dataframe=train_df, vocab=vocab, train=True)\n",
        "      print(\"load dev data\")\n",
        "      dev_data = WSBDataStock(path, label_type=\"volitility\", dataframe=dev_df, vocab=vocab, train=False)\n",
        "      print(train_data.vocab.get_vocab_size())\n",
        "    \n",
        "    \n",
        "    if device == \"gpu\":\n",
        "        device = torch.device('cuda:0')\n",
        "        nbow_model = NBOW(train_data.vocab.get_vocab_size(), NUM_CLASSES=n_classes, DIM_EMB=350).cuda()\n",
        "        X = train_data.XwordList\n",
        "        Y = train_data.Y\n",
        "        losses, accuracies = train_network(nbow_model, X, Y, 10, dev_data, num_classes=n_classes, batchSize=50, device = device)\n",
        "        print(accuracies)\n",
        "        # train_model(nbow_model, X, Y, 1, dev_data, use_cuda=True)\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        nbow_model = NBOW(train_data.vocab.get_vocab_size(), NUM_CLASSES = n_classes, DIM_EMB=350)\n",
        "        X = train_data.XwordList\n",
        "        Y = train_data.Y\n",
        "        losses, accuracies = train_network(nbow_model, X, Y, 2, dev_data, batchSize=50, num_classes=n_classes, device = device)\n",
        "        print(accuracies)\n",
        "        # train_model(nbow_model, X, Y, 1, dev_data, use_cuda=False)\n",
        "\n",
        "    if save_model:\n",
        "        torch.save(nbow_model.state_dict(), \"nbow.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u47usW6LiINC"
      },
      "source": [
        "def attention(path=\"./reddit_wsb.csv\", n_classes=3, label_type=\"volitility\", device=\"gpu\", save_model=True):\n",
        "    if path == \"./reddit_wsb.csv\":\n",
        "      data = load_csv(path, \"reddit\")\n",
        "      vocab = create_vocab(data['title'].values)\n",
        "   \n",
        "    split_point = int(len(data)*0.9)\n",
        "    train_df = data[0:split_point]\n",
        "    dev_df = data[split_point:]\n",
        "\n",
        "    print(\"load train data\")\n",
        "    if path == \"./reddit_wsb.csv\":\n",
        "      train_data = WSBDataStock(path, dataframe=train_df, label_type=\"volitility\", vocab=vocab, train=True)\n",
        "      print(\"load dev data\")\n",
        "      dev_data = WSBDataStock(path, dataframe=dev_df, label_type=\"volitility\", vocab=vocab, train=False)\n",
        "      print(train_data.vocab.get_vocab_size())\n",
        "\n",
        "\n",
        "    if device == \"gpu\":\n",
        "        device = torch.device('cuda:0')\n",
        "        attn_model = AttentionModel(train_data.vocab.get_vocab_size(), DIM_EMB=350, NUM_CLASSES=n_classes).cuda()\n",
        "        X = train_data.XwordList\n",
        "        Y = train_data.Y\n",
        "        losses, accuracies = train_network(attn_model, X, Y, 10, dev_data, batchSize=50, device = device, num_classes=n_classes)\n",
        "        print(accuracies)\n",
        "        # train_model(attn_model, X, Y, 1, dev_data, use_cuda=True)\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        attn_model = AttentionModel(train_data.vocab.get_vocab_size(), DIM_EMB=350, NUM_CLASSES=n_classes)\n",
        "        X = train_data.XwordList\n",
        "        Y = train_data.Y\n",
        "        losses, accuracies = train_network(attn_model, X, Y, 5, dev_data, batchSize=50, device = device, num_classes=n_classes)\n",
        "        print(accuracies)\n",
        "        # train_model(attn_model, X, Y, 1, dev_data, use_cuda=False)\n",
        "\n",
        "    if save_model:\n",
        "        torch.save(attn_model.state_dict(), \"attention.pth\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7lbaeZLiKmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f283b248-9fa0-4de1-f1e6-7fea8f15e3c8"
      },
      "source": [
        "attention(label_type=\"volitility\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load train data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/natural-language-spring-2021/final/model/vocab.py:267: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.dataframe[\"timestamp\"] = pd.to_datetime(self.dataframe[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
            "100%|██████████| 33814/33814 [00:17<00:00, 1895.99it/s]\n",
            "/content/natural-language-spring-2021/final/model/vocab.py:267: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.dataframe[\"timestamp\"] = pd.to_datetime(self.dataframe[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
            "  0%|          | 0/3631 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "set()\n",
            "33814\n",
            "(33814,)\n",
            "33814\n",
            "load dev data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3631/3631 [00:01<00:00, 1954.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "set()\n",
            "3631\n",
            "(3631,)\n",
            "3631\n",
            "27612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/677 [00:00<02:13,  5.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Start Training!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 13/73 [00:00<00:00, 121.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 0 = 232.89992094039917\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 4/677 [00:00<00:21, 31.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7245937758193335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 13/73 [00:00<00:00, 126.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 1 = 230.98315075039864\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 4/677 [00:00<00:21, 31.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7256954007160562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 13/73 [00:00<00:00, 125.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 2 = 228.07288536429405\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 4/677 [00:00<00:21, 30.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7226659322500688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 13/73 [00:00<00:00, 129.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 3 = 225.350560516119\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 4/677 [00:00<00:21, 30.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7138529330762875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 14/73 [00:00<00:00, 131.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 4 = 222.13100445270538\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 4/677 [00:00<00:21, 30.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7105480583861196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 13/73 [00:00<00:00, 126.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 5 = 220.09016385674477\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 4/677 [00:00<00:21, 31.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.6987055907463509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 14/73 [00:00<00:00, 132.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 6 = 216.63122954964638\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 4/677 [00:00<00:21, 31.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.6623519691545029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 13/73 [00:00<00:00, 127.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 7 = 212.44964307546616\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 4/677 [00:00<00:21, 30.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.6766730928118976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 13/73 [00:00<00:00, 124.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 8 = 208.21764680743217\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 4/677 [00:00<00:21, 30.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.6375654089782429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 13/73 [00:00<00:00, 127.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 9 = 204.439277023077\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.615257504819609\n",
            "Finished Training\n",
            "[0.7245937758193335, 0.7256954007160562, 0.7226659322500688, 0.7138529330762875, 0.7105480583861196, 0.6987055907463509, 0.6623519691545029, 0.6766730928118976, 0.6375654089782429, 0.615257504819609]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls6VUcju2oJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f7500d-c391-416e-ff23-566e204df514"
      },
      "source": [
        "nbow()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/natural-language-spring-2021/final/model/vocab.py:267: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.dataframe[\"timestamp\"] = pd.to_datetime(self.dataframe[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
            "\r  0%|          | 0/33814 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "load train data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 33814/33814 [00:17<00:00, 1925.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "set()\n",
            "33814\n",
            "(33814,)\n",
            "33814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/natural-language-spring-2021/final/model/vocab.py:267: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.dataframe[\"timestamp\"] = pd.to_datetime(self.dataframe[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
            "  6%|▌         | 219/3631 [00:00<00:01, 2187.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "load dev data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3631/3631 [00:01<00:00, 1964.15it/s]\n",
            "  0%|          | 0/677 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "set()\n",
            "3631\n",
            "(3631,)\n",
            "3631\n",
            "27612\n",
            "Start Training!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 31/73 [00:00<00:00, 306.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 0 = 380.8832967579365\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 8/677 [00:00<00:09, 71.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.6766730928118976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 32/73 [00:00<00:00, 309.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 1 = 298.5803317129612\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 8/677 [00:00<00:09, 71.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.4378958964472597\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 32/73 [00:00<00:00, 311.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 2 = 255.08943405747414\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 8/677 [00:00<00:09, 71.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7210134949049849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 32/73 [00:00<00:00, 314.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 3 = 246.91498211026192\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 8/677 [00:00<00:09, 70.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7110988708344809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 32/73 [00:00<00:00, 312.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 4 = 248.80612689256668\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 8/677 [00:00<00:09, 71.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7179840264389975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 32/73 [00:00<00:00, 314.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 5 = 253.92767368257046\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 8/677 [00:00<00:09, 71.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7152299641971909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 31/73 [00:00<00:00, 306.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 6 = 256.48755064606667\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 8/677 [00:00<00:09, 71.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7122004957312035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 32/73 [00:00<00:00, 307.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 7 = 267.3550404906273\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 8/677 [00:00<00:09, 71.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7179840264389975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 32/73 [00:00<00:00, 310.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 8 = 267.781591206789\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 8/677 [00:00<00:09, 71.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7141283393004682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 32/73 [00:00<00:00, 310.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss on epoch 9 = 268.04197531938553\n",
            "Evaluation Set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Eval Accuracy: 0.7177086202148169\n",
            "Finished Training\n",
            "[0.6766730928118976, 0.4378958964472597, 0.7210134949049849, 0.7110988708344809, 0.7179840264389975, 0.7152299641971909, 0.7122004957312035, 0.7179840264389975, 0.7141283393004682, 0.7177086202148169]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsyII4O2nEtb"
      },
      "source": [
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Tx1P0xRmDc"
      },
      "source": [
        "results = [0.6766730928118976, 0.4378958964472597, 0.7210134949049849, 0.7110988708344809, 0.7179840264389975, 0.7152299641971909, 0.7122004957312035, 0.7179840264389975, 0.7141283393004682, 0.7177086202148169]\n",
        "x_vals = range(len(results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "NKcfgPCJRgQR",
        "outputId": "07ed18dd-3600-4065-fd74-72ae7ed617fe"
      },
      "source": [
        "plt.plot(x_vals, results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9d8b5730d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5esGINURrbn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}